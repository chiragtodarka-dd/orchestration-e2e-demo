# This file is auto-generated by function_to_operator_generator.py
# Changes will be overwritten.

import os
from typing import Any, Dict, Optional
from datetime import datetime

from airflow.models import BaseOperator
from orchestration.function.function_abstract import ExecutionContext
from orchestration.function.postgres_sql_function import PostgreSQLFunction as PostgresSQLFunctionImplementation

class PostgreSQLFunction(BaseOperator):
    """
    Airflow operator for PostgreSQLFunction.
    This operator is auto-generated.
    """
    
    def __init__(
        self,
        *,
        task_id: str,
        sql_file_path: str,
        use_dict_cursor: bool = True,
        kwargs: Dict[str, Any] = None,
        secret_key: Optional[str] = None,
        **base_kwargs
    ):
        """
        Initialize the PostgreSQL operator.
        
        Args:
            task_id: The task ID for this operator
            sql_file_path: Path to the SQL file to execute
            use_dict_cursor: Whether to use RealDictCursor for query results
            kwargs: Additional parameters to pass to the PostgreSQL function
            secret_key: Optional key for accessing secrets
            **base_kwargs: Additional arguments to pass to BaseOperator
        """
        # Initialize BaseOperator first
        super().__init__(task_id=task_id, **base_kwargs)
        
        # Store operator-specific parameters
        self.sql_file_path = sql_file_path
        self.use_dict_cursor = use_dict_cursor
        self.kwargs = kwargs or {}
        self.secret_key = secret_key
        
        # Store function parameters
        self.function_params = {
            'sql_file_path': self.sql_file_path,
            'use_dict_cursor': self.use_dict_cursor,
            'kwargs': self.kwargs,
            'secret_key': self.secret_key
        }
    
    def execute(self, context: Dict[str, Any]) -> Any:
        """
        Execute the function with the given Airflow context.
        """
        print(f"Executing operator PostgreSQLFunction for task {self.task_id}")
        
        # Get execution date from context
        execution_date = context.get('execution_date', context.get('data_interval_start'))
        if isinstance(execution_date, datetime):
            execution_date = execution_date.strftime('%Y-%m-%d')
        
        # Add execution_date to function parameters
        self.function_params['kwargs']['execution_date'] = execution_date
        
        exec_context = ExecutionContext(
            execution_date=execution_date,
            task_id=self.task_id,
            dag_id=self.dag_id,
            run_id=context.get('run_id'),
            params=context.get('params', {}),
            secret_key=self.secret_key
        )
        
        print(f"Initializing function PostgreSQLFunction with params: {self.function_params} and secret_key: {self.secret_key}")
        function_instance = PostgresSQLFunctionImplementation(
            context=exec_context,
            **self.function_params
        )
        
        try:
            print(f"Calling pre_execute for {self.task_id}")
            function_instance.pre_execute()
            print(f"Calling execute for {self.task_id}")
            result = function_instance.execute()
            print(f"Calling post_execute for {self.task_id}")
            function_instance.post_execute()
            print(f"Calling on_success for {self.task_id}")
            function_instance.on_success()
            return result
        except Exception as e:
            print(f"Exception in {self.task_id}: {e}. Calling on_failure.")
            function_instance.on_failure()
            raise
